{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Differential Privacy: Overview, Advantages, and Limitations\n",
    "\n",
    "## What is Differential Privacy?\n",
    "Differential Privacy (DP) is a mathematical framework for providing privacy guarantees while analyzing and sharing data. The core idea is to ensure that the inclusion or exclusion of any single individual's data does not significantly affect the output of an analysis, thereby protecting their privacy. This is achieved by adding carefully calibrated noise to the data or to the results of computations.\n",
    "\n",
    "The privacy guarantee is quantified by two parameters:\n",
    "- **Epsilon (ε)**: Controls the trade-off between privacy and accuracy; smaller ε provides stronger privacy but potentially less accurate results.\n",
    "- **Delta (δ)**: Represents the probability of failing to achieve the desired privacy level (used in relaxed versions of DP).\n",
    "\n",
    "## Main Advantages\n",
    "1. **Strong Privacy Guarantees**: Protects individuals' data even against adversaries with auxiliary knowledge.\n",
    "2. **Mathematical Rigor**: Provides provable and quantifiable privacy guarantees.\n",
    "3. **Scalability**: Suitable for large datasets and machine learning models.\n",
    "4. **Flexibility**: Can be applied to various applications, including statistics, machine learning, and synthetic data generation.\n",
    "5. **Resilience**: Ensures privacy protection even when multiple analyses are conducted on the same dataset (composition property).\n",
    "\n",
    "## Main Disadvantages\n",
    "1. **Utility Loss**: Adding noise to ensure privacy can degrade the accuracy of results, especially with smaller datasets or low ε values.\n",
    "2. **Complex Implementation**: Requires careful tuning of privacy parameters and understanding of the underlying mathematics.\n",
    "3. **Resource Intensive**: In some cases, computational requirements increase due to the additional noise and constraints.\n",
    "\n",
    "## Limitations\n",
    "1. **Requires Large Datasets**: Differential Privacy works best with large datasets to mitigate utility loss from added noise.\n",
    "2. **No Absolute Privacy**: Privacy guarantees are probabilistic, meaning there is still a small chance of information leakage (controlled by δ).\n",
    "3. **Not a Universal Solution**: DP does not eliminate all privacy risks (e.g., adversaries might infer information indirectly through external data).\n",
    "4. **Interpretability Challenges**: Non-technical stakeholders may find it difficult to interpret and understand ε and δ parameters.\n",
    "\n",
    "## Conclusion\n",
    "Differential Privacy is a powerful tool for balancing the need for data utility and individual privacy. However, its practical implementation requires careful consideration of privacy-utility trade-offs, parameter tuning, and domain-specific requirements.\n"
   ],
   "id": "c11e7cf909cba8d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T14:49:36.421639Z",
     "start_time": "2025-01-30T14:49:35.205368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install diffprivlib\n",
    "\n",
    "import diffprivlib.models as dp"
   ],
   "id": "a44c3e8aad40a3ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: diffprivlib in /home/rkruger/miniconda3/envs/ppml-python/lib/python3.12/site-packages (0.6.5)\r\n",
      "Requirement already satisfied: numpy>=1.21.6 in /home/rkruger/miniconda3/envs/ppml-python/lib/python3.12/site-packages (from diffprivlib) (2.0.1)\r\n",
      "Requirement already satisfied: scikit-learn>=0.24.2 in /home/rkruger/miniconda3/envs/ppml-python/lib/python3.12/site-packages (from diffprivlib) (1.5.2)\r\n",
      "Requirement already satisfied: scipy>=1.7.3 in /home/rkruger/miniconda3/envs/ppml-python/lib/python3.12/site-packages (from diffprivlib) (1.15.1)\r\n",
      "Requirement already satisfied: joblib>=0.16.0 in /home/rkruger/miniconda3/envs/ppml-python/lib/python3.12/site-packages (from diffprivlib) (1.4.2)\r\n",
      "Requirement already satisfied: setuptools>=49.0.0 in /home/rkruger/miniconda3/envs/ppml-python/lib/python3.12/site-packages (from diffprivlib) (75.1.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/rkruger/miniconda3/envs/ppml-python/lib/python3.12/site-packages (from scikit-learn>=0.24.2->diffprivlib) (3.5.0)\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T14:49:36.474066Z",
     "start_time": "2025-01-30T14:49:36.428290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ],
   "id": "8e1e54422f09403d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T14:49:36.666484Z",
     "start_time": "2025-01-30T14:49:36.576500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.loadtxt(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    "                     usecols=(0, 4, 10, 11, 12), delimiter=\",\")\n",
    "y_train = np.loadtxt(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", usecols=14,\n",
    "                     dtype=str, delimiter=\",\")\n",
    "\n",
    "X_test = np.loadtxt(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\",\n",
    "                    usecols=(0, 4, 10, 11, 12), delimiter=\",\", skiprows=1)\n",
    "y_test = np.loadtxt(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\", usecols=14, dtype=str,\n",
    "                    delimiter=\",\", skiprows=1)\n",
    "\n",
    "y_test = np.array([a[:-1] for a in y_test])"
   ],
   "id": "15eddcaac8c888b0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1875401/2344259381.py:5: UserWarning: Input line 32562 contained no data and will not be counted towards `max_rows=50000`.  This differs from the behaviour in NumPy <=1.22 which counted lines rather than rows.  If desired, the previous behaviour can be achieved by using `itertools.islice`.\n",
      "Please see the 1.23 release notes for an example on how to do this.  If you wish to ignore this warning, use `warnings.filterwarnings`.  This warning is expected to be removed in the future and is given only once per `loadtxt` call.\n",
      "  y_train = np.loadtxt(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", usecols=14,\n",
      "/tmp/ipykernel_1875401/2344259381.py:10: UserWarning: Input line 16283 contained no data and will not be counted towards `max_rows=50000`.  This differs from the behaviour in NumPy <=1.22 which counted lines rather than rows.  If desired, the previous behaviour can be achieved by using `itertools.islice`.\n",
      "Please see the 1.23 release notes for an example on how to do this.  If you wish to ignore this warning, use `warnings.filterwarnings`.  This warning is expected to be removed in the future and is given only once per `loadtxt` call.\n",
      "  y_test = np.loadtxt(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\", usecols=14, dtype=str,\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T14:50:41.640206Z",
     "start_time": "2025-01-30T14:50:35.110708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nonprivate_clf = GaussianNB()\n",
    "nonprivate_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Non-private test accuracy: %.2f%%\" %\n",
    "      (accuracy_score(y_test, nonprivate_clf.predict(X_test)) * 100))\n",
    "\n",
    "dp_clf = dp.GaussianNB(epsilon=0.1)\n",
    "\n",
    "dp_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Differentially private test accuracy (epsilon=%.2f): %.2f%%\" %\n",
    "      (dp_clf.epsilon, accuracy_score(y_test, dp_clf.predict(X_test)) * 100))"
   ],
   "id": "624edb8db3798b56",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-private test accuracy: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rkruger/miniconda3/envs/ppml-python/lib/python3.12/site-packages/diffprivlib/models/naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differentially private test accuracy (epsilon=0.10): 0.00%\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T14:49:36.881765Z",
     "start_time": "2025-01-30T14:49:36.779773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('clf', LogisticRegression(solver=\"lbfgs\"))\n",
    "])\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Non-private test accuracy: %.2f%%\" % (accuracy_score(y_test, lr.predict(X_test)) * 100))\n",
    "\n",
    "dp_lr = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('clf', dp.LogisticRegression(epsilon=0.01))\n",
    "])\n",
    "\n",
    "dp_lr.fit(X_train, y_train)\n",
    "print(\"Differentially private test accuracy (epsilon=%.2f): %.2f%%\" %\n",
    "      (dp_lr['clf'].epsilon, accuracy_score(y_test, dp_lr.predict(X_test)) * 100))\n"
   ],
   "id": "65c70d6e5331694a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-private test accuracy: 81.04%\n",
      "Differentially private test accuracy (epsilon=0.01): 23.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rkruger/miniconda3/envs/ppml-python/lib/python3.12/site-packages/diffprivlib/models/logistic_regression.py:239: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T14:49:36.953507Z",
     "start_time": "2025-01-30T14:49:36.936017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = datasets.load_diabetes()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.data,\n",
    "                                                    dataset.target, test_size=0.2)\n",
    "\n",
    "print(\"Train examples: %d, Test examples: %d\" % (X_train.shape[0],\n",
    "                                                 X_test.shape[0]))"
   ],
   "id": "fea6c0cec847b76d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples: 353, Test examples: 89\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T14:49:37.027621Z",
     "start_time": "2025-01-30T14:49:36.985923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LinearRegression as sk_LinearRegression\n",
    "\n",
    "regr = sk_LinearRegression()\n",
    "\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "baseline = r2_score(y_test, regr.predict(X_test))\n",
    "print(\"Non-private baseline: %.2f\" % baseline)\n",
    "\n",
    "from diffprivlib.models import LinearRegression\n",
    "\n",
    "regr = LinearRegression(epsilon=0.01)\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "print(\"R2 score for epsilon=%.2f: %.2f\" % (regr.epsilon, r2_score(y_test, regr.predict(X_test))))"
   ],
   "id": "249400944dc7c5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-private baseline: 0.55\n",
      "R2 score for epsilon=0.01: -23549394.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rkruger/miniconda3/envs/ppml-python/lib/python3.12/site-packages/diffprivlib/models/linear_regression.py:271: PrivacyLeakWarning: Bounds parameters haven't been specified, so falling back to determining bounds from the data.\n",
      "This will result in additional privacy leakage. To ensure differential privacy with no additional privacy loss, specify `bounds_X` and `bounds_y`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
